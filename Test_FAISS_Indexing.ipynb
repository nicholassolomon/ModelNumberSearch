{"cells":[{"cell_type":"markdown","metadata":{"id":"fCkmPEc3PGh7"},"source":["# Test FAISS Indexing"]},{"cell_type":"markdown","metadata":{"id":"fni008SMRW9l"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k80Ky0gxPR_r"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YPsiDsVjPMND"},"outputs":[],"source":["import torch\n","\n","!pip install -quiet sentence-transformers datasets python-Levenshtein\n","!sudo apt-get install libomp-dev\n","\n","if torch.cuda.is_available():\n","  !pip install -q faiss-gpu\n","else:\n","  !pip install -q faiss-cpu\n","\n","import os\n","from google.colab import userdata\n","\n","os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3_jV4lPRn9r"},"outputs":[],"source":["MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n","DATASET = \"blade57/ModelNumbers4Searching_Full\"\n","#DATASET = \"blade57/ModelNumber_small\"\n","SEARCH_FIELD = 'model_search'\n","EMBED_FIELD  = 'embeddings'\n","CSV_FILE_NAME = 'ModelSearchWithEmbeddings_Full.csv'\n","FAISS_INDEX = \"/content/drive/MyDrive/Colab Notebooks/Projects/Semantic Searching Model Identification/Full_Dataset/ModelSearch_Full.faiss\"\n","DB_NO_EMBEDDINGS = \"/content/drive/MyDrive/Colab Notebooks/Projects/Semantic Searching Model Identification/Full_Dataset/ModelNumbers4Searching_Full.csv\"\n","DB_W_EMBEDDINGS = \"/content/drive/MyDrive/Colab Notebooks/Projects/Semantic Searching Model Identification/Full_Dataset/ModelSearchWithEmbeddings_Full.csv\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e7TA-9cERFkP"},"outputs":[],"source":["# Load Model and Create Embedding Function\n","%%capture\n","from sentence_transformers import SentenceTransformer\n","from datasets import load_dataset\n","from Levenshtein import distance\n","import pandas as pd\n","\n","model = SentenceTransformer(MODEL)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZR8LifKBOymN"},"outputs":[],"source":["# functions\n","\n","# embeddings\n","def create_embeddings(text):\n","  embeddings = model.encode([text])\n","  return embeddings\n","\n","def query(search_text, return_no=10):\n","  search_embedding = create_embeddings(search_text)\n","  scores, search_results = ds.get_nearest_examples(EMBED_FIELD,\n","                                                   search_embedding,\n","                                                   k=return_no)\n","  return scores, search_results\n","\n","def query_df(search_text, return_no=10):\n","  search_embedding = create_embeddings(search_text)\n","  scores, search_results = ds.get_nearest_examples(EMBED_FIELD,\n","                                                   search_embedding,\n","                                                   k=return_no)\n","  results = pd.DataFrame({\n","    'scores': scores,\n","    'model_search': search_results['model_search'],\n","    'model_number': search_results['model_number'],\n","    'model_name': search_results['model_name'],\n","    'brand': search_results['brand'],\n","    'search_for': search_text\n","  })\n","  return results, scores, search_results\n","\n","def get_ls_rank(search1, search2):\n","  return distance(s1=str(search1).to_lower(),\n","                  s2=str(search2).to_lower()\n","                  )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VB3sKwBWRhGM"},"outputs":[],"source":["# load dataset\n","ds = load_dataset(DATASET, split='train')\n","\n","# load FAISS index for dataset\n","ds.load_faiss_index(EMBED_FIELD, FAISS_INDEX)\n","\n","print(f\"Records: {len(ds)}\")"]},{"cell_type":"markdown","metadata":{"id":"_XAa4f5mP3Me"},"source":["## Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xeJJJ8uTZim"},"outputs":[],"source":["# process results into df and result sets\n","\n","search_for = 'A436BHT'\n","rows = 10\n","result_df, scores, results = query_df(search_for, rows)\n","\n","# sort by scores (descending)\n","#result_df = result_df.sort_values(by=['scores'], ascending=False)\n","#result_df.head(rows)\n","\n","# get LS rank and resort by LS rank (ascending)\n","result_df['LS_rank'] = result_df['model_search'].apply(lambda x: get_ls_rank(search_for, x))\n","result_df = result_df.sort_values(by=['LS_rank'], ascending=True)\n","\n","result_df.head(rows)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8HukANKebwkV"},"outputs":[],"source":["# check against LS and resort\n","\n","result_df['LS_rank'] = result_df['model_search'].apply(lambda x: get_ls_rank(search_for, x))\n","result_df = result_df.sort_values(by=['LS_rank'], ascending=True)\n","\n","result_df.head(rows)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPkSt/nTAtA1gAORg7F81jX","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
